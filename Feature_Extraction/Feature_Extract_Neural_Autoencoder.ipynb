{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97ae21a8-f549-44df-8847-a65d653db468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import auraloss\n",
    "import collections\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import plotly.graph_objects as go\n",
    "import pretty_midi\n",
    "import pytorch_lightning as pl\n",
    "import pywt\n",
    "import random\n",
    "import scipy.signal\n",
    "import sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "\n",
    "seed_value = 3407\n",
    "torch.manual_seed(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "torch.cuda.manual_seed(seed_value)\n",
    "torch.cuda.manual_seed_all(seed_value)\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d903e9db-b001-4271-b8ca-21c125af63ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        #losses\n",
    "        self.loss_fn_1 = auraloss.freq.RandomResolutionSTFTLoss(\n",
    "                    sample_rate=32000,\n",
    "                    device=\"cuda\"\n",
    "                )\n",
    "        self.loss_fn_2 = auraloss.time.SISDRLoss()\n",
    "        self.loss_fn_3 = torch.nn.L1Loss()\n",
    "        \n",
    "        # Encoder\n",
    "        self.enc_conv1 = nn.Conv1d(1, 8, kernel_size=33, stride=4, padding=16)\n",
    "        self.enc_conv2 = nn.Conv1d(8, 16, kernel_size=17, stride=4, padding=8)\n",
    "        self.enc_conv3 = nn.Conv1d(16, 32, kernel_size=9, stride=2, padding=4)\n",
    "        self.enc_conv4 = nn.Conv1d(32, 64, kernel_size=9, stride=2, padding=4)\n",
    "        self.enc_conv5 = nn.Conv1d(64,128, kernel_size=9, stride=2, padding=4)\n",
    "        self.enc_conv6 = nn.Conv1d(128, 256, kernel_size=9, stride=2, padding=4)\n",
    "        self.enc_conv7 = nn.Conv1d(256, 512, kernel_size=9, stride=2, padding=4)\n",
    "        self.enc_conv8 = nn.Conv1d(512, 1024, kernel_size=9, stride=2, padding=4)\n",
    "        \n",
    "        # Decoder\n",
    "        self.dec_conv1 = nn.ConvTranspose1d(1024, 512, kernel_size=9, stride=2, padding=4, output_padding=1)\n",
    "        self.dec_conv2 = nn.ConvTranspose1d(512, 256, kernel_size=9, stride=2, padding=4, output_padding=0)\n",
    "        self.dec_conv3 = nn.ConvTranspose1d(256, 128, kernel_size=9, stride=2, padding=5, output_padding=0)\n",
    "        self.dec_conv4 = nn.ConvTranspose1d(128, 64, kernel_size=9, stride=2, padding=4, output_padding=0)\n",
    "        self.dec_conv5 = nn.ConvTranspose1d(64,32, kernel_size=9, stride=2, padding=4, output_padding=0)\n",
    "        self.dec_conv6 = nn.ConvTranspose1d(32, 16, kernel_size=9, stride=2, padding=4, output_padding=0)\n",
    "        self.dec_conv7 = nn.ConvTranspose1d(16, 8, kernel_size=21, stride=4, padding=9, output_padding=0)\n",
    "        self.dec_conv8 = nn.ConvTranspose1d(8, 1, kernel_size=37, stride=4, padding=22, output_padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x = self.enc_conv1(x)\n",
    "        x = self.enc_conv2(x)\n",
    "        x = self.enc_conv3(x)\n",
    "        x = self.enc_conv4(x)\n",
    "        x = self.enc_conv5(x)\n",
    "        x = self.enc_conv6(x)\n",
    "        x = self.enc_conv7(x)\n",
    "        x = self.enc_conv8(x)\n",
    "        encoded = x\n",
    "        \n",
    "        # Decoder\n",
    "        x = self.dec_conv1(x)\n",
    "        x = self.dec_conv2(x)\n",
    "        x = self.dec_conv3(x)\n",
    "        x = self.dec_conv4(x)\n",
    "        x = self.dec_conv5(x)\n",
    "        x = self.dec_conv6(x)\n",
    "        x = self.dec_conv7(x)\n",
    "        x = self.dec_conv8(x)\n",
    "\n",
    "        x = x[:,:,:160000]\n",
    "        return x, encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16759b28-d942-4389-9069-c0a7f6ae4f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder.load_from_checkpoint('./final_model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58e9382f-abbe-4972-813c-aef4db9b85d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                         | 22263/27131 [06:03<01:29, 54.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error Error opening '../data/rendered_audio/rendered_audio/d270f326-a3f6-4807-ac06-8716c9166ad1.flac': Format not recognised.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27131/27131 [08:44<00:00, 51.73it/s]\n"
     ]
    }
   ],
   "source": [
    "path = \"../data/rendered_audio/rendered_audio/\"\n",
    "files = os.listdir(path)\n",
    "fs = []\n",
    "embeddings = []\n",
    "transform = torchaudio.transforms.Resample(44100, 32000)\n",
    "for file in tqdm(files):\n",
    "    if \".flac\" in file:\n",
    "        try:\n",
    "            full_path = path + file\n",
    "            audio, _ = torchaudio.load(full_path)\n",
    "            audio = transform(audio)\n",
    "\n",
    "            _, embedding = model(audio.to(model.device).unsqueeze(0))\n",
    "            embeddings.append(embedding.squeeze(0).squeeze(0).detach().cpu().numpy())\n",
    "            fs.append(full_path)\n",
    "        except Exception as e:\n",
    "            print(\"error\", e)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8096dc-c11f-42bd-903d-c6dbcabee572",
   "metadata": {},
   "source": [
    "# Dump output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f297ef-333b-4ae9-8b80-601724c1b7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(embeddings, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733f12e5-f58b-4c73-9d55-7889581fa30a",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08e0d0fc-832f-417c-b165-0f56199c28c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 157)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcc7ad2c-e54b-40e6-b270-489229e11a63",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m emb \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m]\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m emb \u001b[38;5;241m=\u001b[39m [e\u001b[38;5;241m.\u001b[39mflatten() \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m embeddings]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "emb = [e.flatten() for e in embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a90d71e-92ec-4d0a-b3ec-8357a05fd69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3, svd_solver='full')\n",
    "pca_ = pca.fit_transform(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d287a07-9d14-4022-b5fe-76905676029c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmean_model = KMeans(n_clusters=11).fit(emb)\n",
    "labels = kmean_model.predict(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94bd61e-6235-4466-b8c5-66c8b56f4fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_a = []\n",
    "feature_b = []\n",
    "feature_c = []\n",
    "# feature_d = []\n",
    "# feature_e = []\n",
    "\n",
    "for i in pca_:\n",
    "    feature_a.append(i[0])\n",
    "    feature_b.append(i[1])\n",
    "    feature_c.append(i[2])\n",
    "    # feature_d.append(i[3])\n",
    "    # feature_e.append(i[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf77996-0b5a-4f27-8d3d-54bc1c38d7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = [feature_a, feature_b, feature_c]#, feature_d, feature_e]\n",
    "\n",
    "for idx, val in enumerate(plots):\n",
    "    for idx1, val1 in enumerate(plots):\n",
    "        if idx > idx1:\n",
    "            #plotting the results\n",
    "            plt.scatter(val, val1, c=labels)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958c70c4-33fa-45a8-af02-1a36a46b1c72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
