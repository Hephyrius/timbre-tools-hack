{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T15:27:15.087017Z",
     "start_time": "2024-02-23T15:27:08.678960Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Output device: MacBook Pro Speakers (44100Hz, buffer size 512 samples, 2 channels)\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------------------------\n",
    "# 03. Corpus-based analysis and synthesis\n",
    "#\n",
    "# This notebook demonstrates how to:\n",
    "#  - extract features from a pre-recorded corpus of audio (here, a large audio file)\n",
    "#  - perform dimensionality reduction\n",
    "#  - transform feature arrays into a pandas dataframe\n",
    "#  - create interactive plots to play back grains in latent feature space\n",
    "#  - use audio-rate modulation to modulate playback of grains\n",
    "#  - use timeline-based sequencing to trigger playback of grains\n",
    "#\n",
    "# TODO: Different segmentation methods\n",
    "#\n",
    "# Requirements:\n",
    "#   pip3 install numpy librosa scikit-learn ipython matplotlib altair pandas anywidget isobar\n",
    "#------------------------------------------------------------------------------------------------\n",
    "\n",
    "import librosa\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import sklearn.cluster\n",
    "import IPython.display\n",
    "import sklearn.decomposition\n",
    "import sklearn.preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Hide numerical warnings and permit large datasets\n",
    "warnings.filterwarnings('ignore')\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "from signalflow import *\n",
    "graph = AudioGraph()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T15:27:15.116668Z",
     "start_time": "2024-02-23T15:27:14.721537Z"
    }
   },
   "source": [
    "#--------------------------------------------------------------------------------\n",
    "# Load an audio file to analyse and process\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "# filename = \"audio/ligeti-atmospheres.wav\"\n",
    "# filename = \"audio/sunkilmoon-truckers-atlas-loop.wav\"\n",
    "# filename = \"/Volumes/T7_Touch/ocd/generation/data_output/staging/rendered_audio/140e6d3e-f923-4341-a20b-cbf38e85f058.flac\"\n",
    "# filename = \"/Volumes/T7_Touch/ocd/generation/data_output/staging/rendered_audio/510319a4-513f-47f0-97c5-da3fb1e62a68.flac\"\n",
    "\n",
    "buffer = Buffer(filename)\n",
    "IPython.display.Audio(buffer.data, rate=buffer.sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1000/1000 [00:06<00:00, 161.57it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torchaudio\n",
    "import random as r\n",
    "from tqdm import tqdm\n",
    "\n",
    "path = \"/Volumes/T7_Touch/ocd/generation/data_output/staging/rendered_audio/\"\n",
    "files = os.listdir(path)\n",
    "r.shuffle(files)\n",
    "fs = []\n",
    "embeddings = []\n",
    "audio_list = []\n",
    "\n",
    "for file in tqdm(files[:1000]):\n",
    "    if \".flac\" in file:\n",
    "        try:\n",
    "            full_path = path + file\n",
    "            audio, _ = torchaudio.load(full_path)\n",
    "            audio_list.append( audio.squeeze(0).numpy())\n",
    "\n",
    "            \n",
    "            fs.append(full_path)\n",
    "        except Exception as e:\n",
    "            print(\"error\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = np.concatenate(audio_list, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T15:27:23.599066Z",
     "start_time": "2024-02-23T15:27:20.414223Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC coefficient shape: (26917, 20)\n",
      "[[-2.9729  3.162   0.4507 -0.4222 -0.1877 -0.1119 -0.1236 -0.1699]\n",
      " [-0.7176  4.173  -0.7612 -0.8261  0.0896 -0.2896 -0.289  -0.2838]\n",
      " [-0.2065  4.1702 -1.0852 -0.7815  0.0539 -0.3509 -0.2437 -0.291 ]\n",
      " [ 0.1406  4.1059 -1.3023 -0.7566 -0.1064 -0.3528 -0.1043 -0.2919]\n",
      " [ 0.1922  4.0749 -1.4514 -0.8108 -0.0799 -0.4151 -0.1616 -0.3133]\n",
      " [ 0.3341  4.0822 -1.4368 -0.6787 -0.1265 -0.4006 -0.1271 -0.3663]\n",
      " [ 0.3226  4.1156 -1.3874 -0.5511 -0.0314 -0.3809 -0.0883 -0.3145]\n",
      " [ 0.2045  4.1606 -1.1906 -0.714  -0.0363 -0.3259 -0.0795 -0.2811]]\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------------\n",
    "# Set global variables: FFT size, hop size, sample rate\n",
    "#--------------------------------------------------------------------------------\n",
    "fft_size = 16384\n",
    "# fft_size = 4096\n",
    "hop_size = fft_size // 2\n",
    "# sample_rate = buffer.sample_rate\n",
    "sample_rate = 44100\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# Extract MFCC, and rescale to zero-mean, unit-variance.\n",
    "# FluCoMa has a nice interactive explainer that gives some intuition:\n",
    "# https://learn.flucoma.org/reference/mfcc/\n",
    "#--------------------------------------------------------------------------------\n",
    "# X = librosa.feature.mfcc(y=buffer.data[0], sr=sample_rate, n_fft=fft_size, hop_length=hop_size, n_mfcc=20)\n",
    "X = librosa.feature.mfcc(y=buffer, sr=sample_rate, n_fft=fft_size, hop_length=hop_size, n_mfcc=20)\n",
    "X = sklearn.preprocessing.scale(X)\n",
    "X = X.T\n",
    "print(\"MFCC coefficient shape: %s\" % str(X.shape))\n",
    "print(np.round(X[:8,:8], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y shape: (26917, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>centroid</th>\n",
       "      <th>flatness</th>\n",
       "      <th>index</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>duration</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.111015</td>\n",
       "      <td>-0.778469</td>\n",
       "      <td>-0.916196</td>\n",
       "      <td>1449.181696</td>\n",
       "      <td>11156</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.371519</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.403363</td>\n",
       "      <td>0.344357</td>\n",
       "      <td>-0.538042</td>\n",
       "      <td>1512.648117</td>\n",
       "      <td>8440</td>\n",
       "      <td>1</td>\n",
       "      <td>0.185760</td>\n",
       "      <td>0.371519</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.611404</td>\n",
       "      <td>0.751074</td>\n",
       "      <td>-0.073680</td>\n",
       "      <td>1600.866441</td>\n",
       "      <td>9345</td>\n",
       "      <td>2</td>\n",
       "      <td>0.371519</td>\n",
       "      <td>0.371519</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.730186</td>\n",
       "      <td>1.070612</td>\n",
       "      <td>0.299991</td>\n",
       "      <td>1750.350414</td>\n",
       "      <td>11863</td>\n",
       "      <td>3</td>\n",
       "      <td>0.557279</td>\n",
       "      <td>0.371519</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.745089</td>\n",
       "      <td>1.224831</td>\n",
       "      <td>0.256057</td>\n",
       "      <td>1863.748744</td>\n",
       "      <td>13142</td>\n",
       "      <td>4</td>\n",
       "      <td>0.743039</td>\n",
       "      <td>0.371519</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26912</th>\n",
       "      <td>-1.045595</td>\n",
       "      <td>-0.288068</td>\n",
       "      <td>-0.059153</td>\n",
       "      <td>1470.725652</td>\n",
       "      <td>6896</td>\n",
       "      <td>26912</td>\n",
       "      <td>4999.163356</td>\n",
       "      <td>0.371519</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26913</th>\n",
       "      <td>-1.347616</td>\n",
       "      <td>-0.003363</td>\n",
       "      <td>0.635716</td>\n",
       "      <td>1300.324130</td>\n",
       "      <td>13699</td>\n",
       "      <td>26913</td>\n",
       "      <td>4999.349116</td>\n",
       "      <td>0.371519</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26914</th>\n",
       "      <td>-1.438623</td>\n",
       "      <td>0.235462</td>\n",
       "      <td>0.775523</td>\n",
       "      <td>1612.773538</td>\n",
       "      <td>20171</td>\n",
       "      <td>26914</td>\n",
       "      <td>4999.534875</td>\n",
       "      <td>0.371519</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26915</th>\n",
       "      <td>-1.461206</td>\n",
       "      <td>0.292682</td>\n",
       "      <td>0.813081</td>\n",
       "      <td>2054.116129</td>\n",
       "      <td>24089</td>\n",
       "      <td>26915</td>\n",
       "      <td>4999.720635</td>\n",
       "      <td>0.371519</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26916</th>\n",
       "      <td>-1.468011</td>\n",
       "      <td>0.312145</td>\n",
       "      <td>0.818223</td>\n",
       "      <td>2842.721164</td>\n",
       "      <td>26013</td>\n",
       "      <td>26916</td>\n",
       "      <td>4999.906395</td>\n",
       "      <td>0.371519</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26917 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              a         b         c     centroid  flatness  index  \\\n",
       "0      0.111015 -0.778469 -0.916196  1449.181696     11156      0   \n",
       "1      1.403363  0.344357 -0.538042  1512.648117      8440      1   \n",
       "2      1.611404  0.751074 -0.073680  1600.866441      9345      2   \n",
       "3      1.730186  1.070612  0.299991  1750.350414     11863      3   \n",
       "4      1.745089  1.224831  0.256057  1863.748744     13142      4   \n",
       "...         ...       ...       ...          ...       ...    ...   \n",
       "26912 -1.045595 -0.288068 -0.059153  1470.725652      6896  26912   \n",
       "26913 -1.347616 -0.003363  0.635716  1300.324130     13699  26913   \n",
       "26914 -1.438623  0.235462  0.775523  1612.773538     20171  26914   \n",
       "26915 -1.461206  0.292682  0.813081  2054.116129     24089  26915   \n",
       "26916 -1.468011  0.312145  0.818223  2842.721164     26013  26916   \n",
       "\n",
       "         timestamp  duration  cluster  \n",
       "0         0.000000  0.371519        3  \n",
       "1         0.185760  0.371519        2  \n",
       "2         0.371519  0.371519        1  \n",
       "3         0.557279  0.371519        1  \n",
       "4         0.743039  0.371519        1  \n",
       "...            ...       ...      ...  \n",
       "26912  4999.163356  0.371519        0  \n",
       "26913  4999.349116  0.371519        0  \n",
       "26914  4999.534875  0.371519        0  \n",
       "26915  4999.720635  0.371519        0  \n",
       "26916  4999.906395  0.371519        0  \n",
       "\n",
       "[26917 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------------\n",
    "# Perform Principal Component Analysis (PCA) to reduce the dimensionality of\n",
    "# each input MFCC frame, and extract various manually-specified features.\n",
    "#--------------------------------------------------------------------------------\n",
    "model = sklearn.decomposition.PCA(n_components=3, whiten=True)\n",
    "model.fit(X)\n",
    "Y = model.transform(X)\n",
    "print(\"Y shape: %s\" % str(Y.shape))\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# Create data series, containing per-segment properties which are later needed\n",
    "# for display and playback:\n",
    "#  - ordinal index\n",
    "#  - timestamp (in seconds)\n",
    "#  - duration (the same for every block, as we're using identically-sized blocks)\n",
    "#--------------------------------------------------------------------------------\n",
    "index = np.arange(len(Y))\n",
    "timestamp = index * hop_size / sample_rate\n",
    "duration = fft_size / sample_rate\n",
    "duration_array = np.array([duration] * len(Y))\n",
    "\n",
    "def floats_to_ordinals(floats):\n",
    "    sorted_indices = np.argsort(floats)\n",
    "    positions = np.argsort(sorted_indices)\n",
    "    return positions.tolist()\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# Manually extract a few features to add to the data frame:\n",
    "#  - spectral centroid\n",
    "#  - spectral flatness\n",
    "#  - k-means cluster\n",
    "#--------------------------------------------------------------------------------\n",
    "centroid = librosa.feature.spectral_centroid(y=buffer, sr=44100, n_fft=fft_size, hop_length=hop_size)[0]\n",
    "flatness = librosa.feature.spectral_flatness(y=buffer, n_fft=fft_size, hop_length=hop_size)[0]\n",
    "flatness = floats_to_ordinals(flatness)\n",
    "kmeans = sklearn.cluster.KMeans(n_clusters=4)\n",
    "labels = kmeans.fit_predict(Y)\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# Aggregate all features into a pandas DataFrame, with columns for each feature\n",
    "# and a row for each segment\n",
    "#--------------------------------------------------------------------------------\n",
    "df = pd.DataFrame({\n",
    "    \"a\": Y[:,0],\n",
    "    \"b\": Y[:,1],\n",
    "    \"c\": Y[:,2],\n",
    "    \"centroid\": centroid,\n",
    "    \"flatness\": flatness,\n",
    "    \"index\": index,\n",
    "    \"timestamp\": timestamp,\n",
    "    \"duration\": duration_array,\n",
    "    \"cluster\": labels,\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = Buffer(buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T15:27:31.343257Z",
     "start_time": "2024-02-23T15:27:31.211220Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6be01e79226748e99552a7415c9e7323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "JupyterChart(spec={'config': {'view': {'continuousWidth': 300, 'continuousHeight': 300}}, 'data': {'name': 'da…"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------------\n",
    "# Altair scatter plot displaying each grain's location within feature space,\n",
    "# with a point-based selector to trigger playback of grains\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "chart = alt.Chart(df, width=800, height=500)\n",
    "chart = chart.mark_circle(size=40)\n",
    "chart = chart.encode(x=alt.X(\"a\"),\n",
    "                     y=alt.Y(\"b\"),\n",
    "                     color=alt.Color('timestamp').scale(scheme=\"plasma\"),\n",
    "                     tooltip=[\"index\", \"timestamp\"])\n",
    "\n",
    "selector = alt.selection_point(name=\"point\",\n",
    "                               on='mouseover',\n",
    "                               nearest=True)\n",
    "chart = chart.add_params(selector)\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# SegmentedGranulator plays back a segment of the input file when triggered\n",
    "#--------------------------------------------------------------------------------\n",
    "granulator = SegmentedGranulator(buffer,\n",
    "                                 df.timestamp,\n",
    "                                 df.duration)\n",
    "# granulator.set_buffer(\"envelope\", EnvelopeBuffer(\"hanning\"))\n",
    "granulator.set_buffer(\"envelope\", EnvelopeBuffer(\"linear-decay\"))\n",
    "#granulator.set_buffer(\"envelope\", EnvelopeBuffer(\"triangle\"))\n",
    "attenuated = granulator * 0.75\n",
    "attenuated.play()\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# Altair callback to trigger a grain on hover\n",
    "#--------------------------------------------------------------------------------\n",
    "def on_select(change):\n",
    "    value = change[\"new\"].value\n",
    "    if value:\n",
    "        index = value[0]\n",
    "        granulator.trigger(\"trigger\", index)\n",
    "        granulator.index = index\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# Add Jupyter interactivity\n",
    "#--------------------------------------------------------------------------------\n",
    "jchart = alt.JupyterChart(chart)\n",
    "jchart.selections.observe(on_select, [\"point\"])\n",
    "jchart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------\n",
    "# This example demonstrates playing features in real-time, using SignalFlow\n",
    "# LFO objects to modulate the X/Y position in feature space.\n",
    "#\n",
    "# The NearestNeighbour node performs a search for the nearest datapoint to\n",
    "# the specified `target` coordinate.\n",
    "# \n",
    "# The signalflow_analysis library contains the AudioFeatureBuffer object,\n",
    "# which encodes N-dimensional frame-wise feature properties. AudioFeatureBuffer\n",
    "# is a subclass of the generic \"Buffer\" signalflow class.\n",
    "#\n",
    "#  - Each channel of the buffer corresponds to a feature\n",
    "#  - Each sample in the buffer corresponds to a segment (block) of the input\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "from signalflow_analysis import *\n",
    "\n",
    "xpos = SineLFO(0.5, -1, 1)\n",
    "ypos = SineLFO(0.71, -1, 1)\n",
    "feature_buffer = AudioFeatureBuffer([df.a, df.b])\n",
    "nearest_index = NearestNeighbour(feature_buffer, target=[xpos, ypos])\n",
    "player = SegmentedGranulator(buffer=buffer,\n",
    "                             onset_times=df.timestamp,\n",
    "                             durations=df.duration,\n",
    "                             index=nearest_index,\n",
    "                             clock=RandomImpulse(5))\n",
    "attenuated = player * 0.5\n",
    "attenuated.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------\n",
    "# Modulate playback parameters interactively.\n",
    "#--------------------------------------------------------------------------------\n",
    "player.clock = RandomImpulse(20)\n",
    "nearest_index.target = [xpos, ypos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------\n",
    "# Example using the isobar sister library for sequencing note events.\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "from isobar import *\n",
    "\n",
    "class NearestNeighbourTrigger (Patch):\n",
    "    #--------------------------------------------------------------------------------\n",
    "    # This patch encapsulates a granulator that plays back grains selected via\n",
    "    # a feature buffer, when triggered.\n",
    "    #--------------------------------------------------------------------------------\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        x = self.add_input(\"centroid\")\n",
    "        y = self.add_input(\"flatness\")\n",
    "        feature_buffer = AudioFeatureBuffer([df.centroid, df.flatness])\n",
    "        nn = NearestNeighbour(feature_buffer, [x, y])\n",
    "        granulator = SegmentedGranulator(buffer,\n",
    "                                         df.timestamp,\n",
    "                                         df.duration * 0.2,\n",
    "                                         index=nn)\n",
    "        # how to create envelope buffer from segments / shape?\n",
    "        granulator.set_buffer(\"envelope\", EnvelopeBuffer(\"linear-decay\"))\n",
    "        delay = AllpassDelay(granulator, 0.1, feedback=0.9)\n",
    "        output = granulator + delay * 0.5\n",
    "        self.set_output(output)\n",
    "        self.set_trigger_node(granulator)\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# Create the patch and connect it to the graph.\n",
    "#--------------------------------------------------------------------------------\n",
    "nnpatch = NearestNeighbourTrigger()\n",
    "nnpatch.play()\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# Create a 150bpm timeline.\n",
    "#--------------------------------------------------------------------------------\n",
    "timeline = Timeline(100, output_device=SignalFlowOutputDevice(graph=graph))\n",
    "timeline.background()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeline.schedule({\n",
    "    \"patch\": nnpatch,\n",
    "    \"type\": \"trigger\",\n",
    "    \"duration\": 0.5,\n",
    "    \"params\": {\n",
    "        # \"centroid\": PSequence([9000, 200, 9000, 100, 7000]) + PWhite(-200, 1000),\n",
    "        # \"flatness\": PSequence([100, 3000, 2000, 3000]) + PWhite(-500, 500)\n",
    "        \"centroid\": PSequence([0 ]) + PWhite(-200, 1000),\n",
    "        \"flatness\": PSequence([100, 3000, 2000]) + PWhite(-500, 500)\n",
    "    }\n",
    "}, name=\"track\", replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T15:12:59.368125Z",
     "start_time": "2024-02-23T15:12:59.341525Z"
    }
   },
   "outputs": [],
   "source": [
    " timeline.clear()\n",
    "graph.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
